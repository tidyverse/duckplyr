% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/io2.R
\name{duck_file}
\alias{duck_file}
\alias{duck_parquet}
\alias{duck_csv}
\alias{duck_json}
\title{Read Parquet, CSV, and other files using DuckDB}
\usage{
duck_parquet(path, ..., lazy = TRUE, options = list())

duck_csv(path, ..., lazy = TRUE, options = list())

duck_json(path, ..., lazy = TRUE, options = list())

duck_file(path, table_function, ..., lazy = TRUE, options = list())
}
\arguments{
\item{path}{Path to files, glob patterns \code{*} and \verb{?} are supported.}

\item{...}{These dots are for future extensions and must be empty.}

\item{lazy}{Logical, whether to create a lazy duckplyr frame.
If \code{TRUE} (the default), \code{\link[dplyr:compute]{dplyr::collect()}} must be called before the data can be accessed.}

\item{options}{Arguments to the DuckDB function
indicated by \code{table_function}.}

\item{table_function}{The name of a table-valued
DuckDB function such as \code{"read_parquet"},
\code{"read_csv"}, \code{"read_csv_auto"} or \code{"read_json"}.}
}
\value{
A duckplyr frame, see \code{\link[=as_duck_tbl]{as_duck_tbl()}} for details.
}
\description{
These functions ingest data from a file.
In many cases, these functions return immediately because they only read the metadata.
The actual data is only read when it is actually processed.

\code{duck_parquet()} reads a CSV file using DuckDB's \code{read_parquet()} table function.

\code{duck_csv()} reads a CSV file using DuckDB's \code{read_csv_auto()} table function.

\code{duck_json()} reads a JSON file using DuckDB's \code{read_json()} table function.

\code{duck_file()} uses arbitrary readers to read data.
See \url{https://duckdb.org/docs/data/overview} for a documentation
of the available functions and their options.
To read multiple files with the same schema,
pass a wildcard or a character vector to the \code{path} argument,
}
\details{
By default, a lazy duckplyr frame is created.
This means that all the data can be shown and all dplyr verbs can be used,
but attempting to access the columns of the data frame or using an unsupported verb,
data type, or function will result in an error.
Pass \code{lazy = FALSE} to transparently switch to local processing as needed,
or use \code{\link[dplyr:compute]{dplyr::collect()}} to explicitly materialize and continue local processing.
}
\examples{
# Create simple CSV file
path <- tempfile("duckplyr_test_", fileext = ".csv")
write.csv(data.frame(a = 1:3, b = letters[4:6]), path, row.names = FALSE)

# Reading is immediate
df <- duck_csv(path)

# Names are always available
names(df)

# Materialization upon access is turned off by default
try(print(df$a))

# Materialize explicitly
collect(df)$a

# Automatic materialization with lazy = FALSE
df <- duck_csv(path, lazy = FALSE)
df$a

# Specify column types
duck_csv(
  path,
  options = list(delim = ",", types = list(c("DOUBLE", "VARCHAR")))
)

# Create and read a simple JSON file
path <- tempfile("duckplyr_test_", fileext = ".json")
writeLines('[{"a": 1, "b": "x"}, {"a": 2, "b": "y"}]', path)

# Reading needs the json extension
duck_exec("INSTALL json")
duck_exec("LOAD json")
duck_json(path)
}
