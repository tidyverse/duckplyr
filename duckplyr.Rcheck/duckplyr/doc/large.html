<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Large data</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Large data</h1>



<p>Working with large datasets in R can be challenging, especially when
performance and memory constraints are a concern. The duckplyr package,
built on top of DuckDB, offers a powerful solution by enabling efficient
data manipulation using familiar dplyr syntax. This article explores
strategies for handling large datasets with duckplyr, covering
ingestion, materialization of intermediate and final results, and good
practice.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(conflicted)</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="fu">library</span>(duckplyr)</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="fu">conflict_prefer</span>(<span class="st">&quot;filter&quot;</span>, <span class="st">&quot;dplyr&quot;</span>)</span></code></pre></div>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Data frames and other objects in R are stored in RAM. This can become
problematic:</p>
<ul>
<li>Data must be loaded into RAM first, even if only part of it is
needed.</li>
<li>Data must be stored in RAM, even if it is not used.</li>
<li>RAM is limited, and data sets can be larger than the available
RAM.</li>
</ul>
<p>A variety of tools have been developed to work with large data sets,
also in R. One example is the dbplyr package, a dplyr backend that
connects to SQL databases and is designed to work with various databases
that support SQL. This is a viable approach if the data is already
stored in a database, or if the data is stored in Parquet or CSV files
and loaded as a lazy table via <code>duckdb::tbl_file()</code>.</p>
<p>The dbplyr package translates dplyr code to SQL. The syntax and
semantics are very similar, but not identical to plain dplyr. In
contrast, the duckplyr package aims to be a fully compatible drop-in
replacement for dplyr, with <em>exactly</em> the same syntax and
semantics:</p>
<ul>
<li>Input and output are data frames or tibbles.</li>
<li>All dplyr verbs are supported, with fallback.</li>
<li>All R data types and functions are supported, with fallback.</li>
<li>No SQL is generated, instead, DuckDB’s “relational” interface is
used.</li>
</ul>
<p>Full compatibility means fewer surprises and less cognitive load for
the user. With DuckDB as the backend, duckplyr can also handle large
data sets that do not fit into RAM, keeping full dplyr compatibility.
The tools for bringing data into and out of R memory are modeled after
the dplyr and dbplyr packages, and are described in the following
sections.</p>
<p>See <code>vignette(&quot;prudence&quot;)</code> on eager and lazy data,
<code>vignette(&quot;limits&quot;)</code> for limitations in the translation
employed by duckplyr, <code>vignette(&quot;duckdb&quot;)</code> for a way to
overcome these limitations, and <code>vignette(&quot;fallback&quot;)</code> for
more information on fallback.</p>
</div>
<div id="to-duckplyr" class="section level2">
<h2>To duckplyr</h2>
<p>The <code>duckdb_tibble()</code> function creates a duckplyr data
frame from vectors:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">duckdb_tibble</span>(<span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">y =</span> letters[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>])</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>df</span></code></pre></div>
<p>The <code>duckdb_tibble()</code> function is a drop-in replacement
for <code>tibble()</code>, and can be used in the same way.</p>
<p>Similarly, <code>as_duckdb_tibble()</code> can be used to convert a
data frame or another object to a duckplyr data frame:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="fu">flights_df</span>() <span class="sc">|&gt;</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>  <span class="fu">as_duckdb_tibble</span>()</span></code></pre></div>
<p>Existing code that uses DuckDB via dbplyr can also take advantage.
The following code creates a DuckDB connection and writes a data frame
to a table:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>path_duckdb <span class="ot">&lt;-</span> <span class="fu">tempfile</span>(<span class="at">fileext =</span> <span class="st">&quot;.duckdb&quot;</span>)</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>con <span class="ot">&lt;-</span> DBI<span class="sc">::</span><span class="fu">dbConnect</span>(duckdb<span class="sc">::</span><span class="fu">duckdb</span>(path_duckdb))</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>DBI<span class="sc">::</span><span class="fu">dbWriteTable</span>(con, <span class="st">&quot;data&quot;</span>, <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">y =</span> letters[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>]))</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>dbplyr_data <span class="ot">&lt;-</span> <span class="fu">tbl</span>(con, <span class="st">&quot;data&quot;</span>)</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>dbplyr_data</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>dbplyr_data <span class="sc">|&gt;</span></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>  <span class="fu">explain</span>()</span></code></pre></div>
<p>The <code>explain()</code> output shows that the data is actually
coming from a DuckDB table. The <code>as_duckdb_tibble()</code> function
can then be used to seamlessly convert the data to a duckplyr frame:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>dbplyr_data <span class="sc">|&gt;</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>  <span class="fu">as_duckdb_tibble</span>()</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>dbplyr_data <span class="sc">|&gt;</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>  <span class="fu">as_duckdb_tibble</span>() <span class="sc">|&gt;</span></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>  <span class="fu">explain</span>()</span></code></pre></div>
<p>This only works for DuckDB connections. For other databases, turn the
data into an R data frame or export it to a file before using
<code>as_duckdb_tibble()</code>.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>DBI<span class="sc">::</span><span class="fu">dbDisconnect</span>(con)</span></code></pre></div>
<p>For other common cases, the <code>duckdb_tibble()</code> function
fails with a helpful error message:</p>
<ul>
<li>duckplyr does not support <code>group_by()</code>:</li>
</ul>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="fu">duckdb_tibble</span>(<span class="at">a =</span> <span class="dv">1</span>) <span class="sc">|&gt;</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>  <span class="fu">group_by</span>(a) <span class="sc">|&gt;</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>  <span class="fu">as_duckdb_tibble</span>()</span></code></pre></div>
<ul>
<li>duckplyr does not support <code>rowwise()</code>:</li>
</ul>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="fu">duckdb_tibble</span>(<span class="at">a =</span> <span class="dv">1</span>) <span class="sc">|&gt;</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>  <span class="fu">rowwise</span>() <span class="sc">|&gt;</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>  <span class="fu">as_duckdb_tibble</span>()</span></code></pre></div>
<ul>
<li>Use <code>read_csv_duckdb()</code> to read with the built-in
reader:</li>
</ul>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>readr<span class="sc">::</span><span class="fu">read_csv</span>(<span class="st">&quot;a</span><span class="sc">\n</span><span class="st">1&quot;</span>, <span class="at">show_col_types =</span> <span class="cn">FALSE</span>) <span class="sc">|&gt;</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>  <span class="fu">as_duckdb_tibble</span>()</span></code></pre></div>
<p>In all cases, <code>as_tibble()</code> can be used to proceed with
the existing code.</p>
</div>
<div id="from-files" class="section level2">
<h2>From files</h2>
<p>DuckDB supports data ingestion from CSV, Parquet, and JSON files. The
<code>read_csv_duckdb()</code> function accepts a file path and returns
a duckplyr frame.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>path_csv_1 <span class="ot">&lt;-</span> <span class="fu">tempfile</span>(<span class="at">fileext =</span> <span class="st">&quot;.csv&quot;</span>)</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="fu">writeLines</span>(<span class="st">&quot;x,y</span><span class="sc">\n</span><span class="st">1,a</span><span class="sc">\n</span><span class="st">2,b</span><span class="sc">\n</span><span class="st">3,c&quot;</span>, path_csv_1)</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="fu">read_csv_duckdb</span>(path_csv_1)</span></code></pre></div>
<p>Reading multiple files is also supported:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>path_csv_2 <span class="ot">&lt;-</span> <span class="fu">tempfile</span>(<span class="at">fileext =</span> <span class="st">&quot;.csv&quot;</span>)</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a><span class="fu">writeLines</span>(<span class="st">&quot;x,y</span><span class="sc">\n</span><span class="st">4,d</span><span class="sc">\n</span><span class="st">5,e</span><span class="sc">\n</span><span class="st">6,f&quot;</span>, path_csv_2)</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a><span class="fu">read_csv_duckdb</span>(<span class="fu">c</span>(path_csv_1, path_csv_2))</span></code></pre></div>
<p>The <code>options</code> argument can be used to control the
reading.</p>
<p>Similarly, the <code>read_parquet_duckdb()</code> and
<code>read_json_duckdb()</code> functions can be used to read Parquet
and JSON files, respectively.</p>
<p>For reading from HTTPS or S3 URLs, the <a href="https://duckdb.org/docs/extensions/httpfs/overview.html">httpfs
extension</a> must be installed and loaded in each session.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="fu">db_exec</span>(<span class="st">&quot;INSTALL httpfs&quot;</span>)</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="fu">db_exec</span>(<span class="st">&quot;LOAD httpfs&quot;</span>)</span></code></pre></div>
<p>Installation is fast if the extension is already installed. Once
loaded, the <code>read_csv_duckdb()</code>,
<code>read_parquet_duckdb()</code>, and <code>read_json_duckdb()</code>
functions can be used with URLs:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>url <span class="ot">&lt;-</span> <span class="st">&quot;https://blobs.duckdb.org/flight-data-partitioned/Year=2024/data_0.parquet&quot;</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>flights_parquet <span class="ot">&lt;-</span> <span class="fu">read_parquet_duckdb</span>(url)</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>flights_parquet</span></code></pre></div>
<p>In all cases, the data is read lazily: only the metadata is read
initially, and the data is read as required. This means that data can be
read from files that are larger than the available RAM. The Parquet
format is particularly efficient for this purpose, as it stores data in
a columnar format and allows reading only the columns that are required.
See <code>vignette(&quot;prudence&quot;)</code> for more details on the concept of
lazy data.</p>
</div>
<div id="from-duckdb" class="section level2">
<h2>From DuckDB</h2>
<p>In addition to <code>as_duckdb_tibble()</code>, arbitrary DuckDB
queries can be executed and the result can be converted to a duckplyr
frame. For this, <a href="https://duckdb.org/docs/sql/statements/attach.html">attach</a> an
existing DuckDB database first:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>sql_attach <span class="ot">&lt;-</span> <span class="fu">paste0</span>(</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>  <span class="st">&quot;ATTACH DATABASE &#39;&quot;</span>,</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a>  path_duckdb,</span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a>  <span class="st">&quot;&#39; AS external (READ_ONLY)&quot;</span></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>)</span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a><span class="fu">db_exec</span>(sql_attach)</span></code></pre></div>
<p>Then, use <code>read_sql_duckdb()</code> to execute a query and
return a duckplyr frame:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="fu">read_sql_duckdb</span>(<span class="st">&quot;SELECT * FROM external.data&quot;</span>)</span></code></pre></div>
</div>
<div id="materialization" class="section level2">
<h2>Materialization</h2>
<p>In dbplyr, <code>compute()</code> is used to materialize a lazy table
in a temporary table on the database, and <code>collect()</code> is used
to bring the data into R memory. This interface works exactly the same
in duckplyr:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a>simple_data <span class="ot">&lt;-</span></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>  <span class="fu">duckdb_tibble</span>(<span class="at">a =</span> <span class="dv">1</span>) <span class="sc">|&gt;</span></span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">b =</span> <span class="dv">2</span>)</span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a>simple_data <span class="sc">|&gt;</span></span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a>  <span class="fu">explain</span>()</span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a>simple_data_computed <span class="ot">&lt;-</span></span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a>  simple_data <span class="sc">|&gt;</span></span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a>  <span class="fu">compute</span>()</span></code></pre></div>
<p>The <code>compute.duckplyr_df()</code> function returns a duckplyr
frame that is materialized in a temporary table. The return value of the
function is a duckplyr frame that can be used in further computations.
The materialization is done in a temporary table, so the data is not
persisted after the session ends:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a>simple_data_computed <span class="sc">|&gt;</span></span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>  <span class="fu">explain</span>()</span></code></pre></div>
<p>The <code>collect()</code> function brings the data into R memory and
returns a plain tibble:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="fu">duckdb_tibble</span>(<span class="at">a =</span> <span class="dv">1</span>) <span class="sc">|&gt;</span></span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">b =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span></span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a>  <span class="fu">collect</span>()</span></code></pre></div>
</div>
<div id="to-files" class="section level2">
<h2>To files</h2>
<p>To materialize data in a persistent file, the
<code>compute_csv()</code> and <code>compute_parquet()</code> functions
can be used. The <code>compute_csv()</code> function writes the data to
a CSV file:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>path_csv_out <span class="ot">&lt;-</span> <span class="fu">tempfile</span>(<span class="at">fileext =</span> <span class="st">&quot;.csv&quot;</span>)</span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a><span class="fu">duckdb_tibble</span>(<span class="at">a =</span> <span class="dv">1</span>) <span class="sc">|&gt;</span></span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">b =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span></span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a>  <span class="fu">compute_csv</span>(path_csv_out)</span>
<span id="cb19-5"><a href="#cb19-5" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" tabindex="-1"></a><span class="fu">writeLines</span>(<span class="fu">readLines</span>(path_csv_out))</span></code></pre></div>
<p>The <code>compute_parquet()</code> function writes the data to a
Parquet file:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>path_parquet_out <span class="ot">&lt;-</span> <span class="fu">tempfile</span>(<span class="at">fileext =</span> <span class="st">&quot;.parquet&quot;</span>)</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a><span class="fu">duckdb_tibble</span>(<span class="at">a =</span> <span class="dv">1</span>) <span class="sc">|&gt;</span></span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">b =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span></span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a>  <span class="fu">compute_parquet</span>(path_parquet_out) <span class="sc">|&gt;</span></span>
<span id="cb20-5"><a href="#cb20-5" tabindex="-1"></a>  <span class="fu">explain</span>()</span></code></pre></div>
<p>Just like with <code>compute.duckplyr_df()</code>, the return value
of <code>compute_csv()</code> and <code>compute_parquet()</code> is a
duckplyr frame that uses the created CSV or Parquet file and can be used
in further computations. At the time of writing, direct JSON export is
not supported.</p>
</div>
<div id="memory-usage" class="section level2">
<h2>Memory usage</h2>
<p>Computations carried out by DuckDB allocate RAM in the context of the
R process. This memory separate from the memory used by R objects, and
is managed by DuckDB. Limit the memory used by DuckDB by setting a
pragma with <code>db_exec()</code>:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a><span class="fu">read_sql_duckdb</span>(<span class="st">&quot;SELECT current_setting(&#39;memory_limit&#39;) AS memlimit&quot;</span>)</span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a><span class="fu">db_exec</span>(<span class="st">&quot;PRAGMA memory_limit = &#39;1GB&#39;&quot;</span>)</span>
<span id="cb21-4"><a href="#cb21-4" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" tabindex="-1"></a><span class="fu">read_sql_duckdb</span>(<span class="st">&quot;SELECT current_setting(&#39;memory_limit&#39;) AS memlimit&quot;</span>)</span></code></pre></div>
<p>See <a href="https://duckdb.org/docs/configuration/overview.html">the
DuckDB documentation</a> for other configuration options.</p>
</div>
<div id="the-big-picture" class="section level2">
<h2>The big picture</h2>
<p>The functions shown in this vignette allow the construction of data
transformation pipelines spanning multiple data sources and data that is
too large to fit into memory. Full compatibility with dplyr is provided,
so existing code can be used with duckplyr with minimal changes. The
lazy computation of duckplyr frames allows for efficient data
processing, as only the required data is read from disk. The
materialization functions allow the data to be persisted in temporary
tables or files, depending on the use case. A typical workflow might
look like this:</p>
<ul>
<li>Prepare all data sources as duckplyr frames: local data frames and
files</li>
<li>Combine the data sources using dplyr verbs</li>
<li>Preview intermediate results as usual: the computation will be
faster because only the first few rows are requested</li>
<li>To avoid rerunning the whole pipeline all over, use
<code>compute.duckplyr_df()</code> or <code>compute_parquet()</code> to
materialize any intermediate result that is too large to fit into
memory</li>
<li>Collect the final result using <code>collect.duckplyr_df()</code> or
write it to a file using <code>compute_csv()</code> or
<code>compute_parquet()</code></li>
</ul>
<p>There is a caveat: due to the design of duckplyr, if a dplyr verb is
not supported or uses a function that is not supported, the data will be
read into memory before being processed further. By default, if the data
pipeline starts with an ingestion function, the data will only be read
into memory if it has less than 1 million cells or values in the
table:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a>flights_parquet <span class="sc">|&gt;</span></span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a>  <span class="fu">group_by</span>(Month)</span></code></pre></div>
<p>Because <code>group_by()</code> is not supported, the data will be
attempted to read into memory before the <code>group_by()</code>
operation is executed. Once the data is small enough to fit into memory,
this works transparently.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a>flights_parquet <span class="sc">|&gt;</span></span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a>  <span class="fu">count</span>(Month, DayofMonth) <span class="sc">|&gt;</span></span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a>  <span class="fu">group_by</span>(Month)</span></code></pre></div>
<p>See <code>vignette(&quot;prudence&quot;)</code> for the concepts and mechanisms
at play, and <code>vignette(&quot;fallback&quot;)</code> for a detailed
explanation of the fallback mechanism.</p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
