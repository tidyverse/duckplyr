---
title: "Funneling"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{10 Funneling}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
clean_output <- function(x, options) {
  x <- gsub("0x[0-9a-f]+", "0xdeadbeef", x)
  x <- gsub("dataframe_[0-9]*_[0-9]*", "      dataframe_42_42      ", x)
  x <- gsub("[0-9]*\\.___row_number ASC", "42.___row_number ASC", x)
  x <- gsub("â”€", "-", x)
  x
}

local({
  hook_source <- knitr::knit_hooks$get("document")
  knitr::knit_hooks$set(document = clean_output)
})

knitr::opts_chunk$set(
  collapse = TRUE,
  eval = identical(Sys.getenv("IN_PKGDOWN"), "true") || (getRversion() >= "4.1"),
  comment = "#>"
)

Sys.setenv(DUCKPLYR_FALLBACK_COLLECT = 0)
```

This vignette discusses eager and lazy computation, and funneling.

```{r attach}
library(conflicted)
library(dplyr)
conflict_prefer("filter", "dplyr")
```

## Introduction

Data frames backed by duckplyr, with class `"duckplyr_df"`, behave as regular data frames in almost all respects.
In particular, direct column access like `df$x`, or retrieving the number of rows with `nrow()`, works identically.
Conceptually, duckplyr frames are "eager": from a user's perspective, they behave like regular data frames.

```{r}
df <- duckplyr::duckdb_tibble(x = 1:5)
df
class(df)
df$x
nrow(df)
```

Under the hood, two key differences provide improved performance and usability:
lazy materialization and funneling.

## Eager and lazy computation

For a duckplyr frame that is the result of a dplyr operation, accessing column data or retrieving the number of rows will trigger a computation that is carried out by DuckDB, not dplyr.
In this sense, duckplyr frames are also "lazy": the computation is deferred until the last possible moment, allowing DuckDB to optimize the whole pipeline.
This is explained in the following example that computes the mean arrival delay for flights departing from Newark airport (EWR) by day and month:

```{r}
flights_df <- duckplyr::flights_df()

flights_duckdb <- 
  flights_df |> 
  duckplyr::as_duckdb_tibble()

system.time(
  mean_arr_delay_ewr <- 
    flights_duckdb |> 
    filter(origin == "EWR", !is.na(arr_delay)) |> 
    summarize(
      .by = month,
      mean_arr_delay = mean(arr_delay),
      min_arr_delay = min(arr_delay),
      max_arr_delay = max(arr_delay),
      median_arr_delay = median(arr_delay),
    )
)
```

Setting up the pipeline is fast, the size of the data does not affect the setup costs.
Because the computation is deferred, DuckDB can optimize the whole pipeline, which can be seen in the output below:

```{r}
mean_arr_delay_ewr |> 
  explain()
```

The first step is to prune the unneeded columns, only `origin`, `month`, and `arr_delay` are kept.
The result becomes available when accessed:

```{r}
system.time(mean_arr_delay_ewr$mean_arr_delay[[1]])
```

This is similar to lazy tables in dbplyr and dtplyr.
In contrast, with dplyr, each intermediate step is computed right away:

```{r}
system.time(
  flights_df |> 
    filter(origin == "EWR", !is.na(arr_delay)) |> 
    summarize(
      .by = c(month, day),
      mean_arr_delay = mean(arr_delay),
      min_arr_delay = min(arr_delay),
      max_arr_delay = max(arr_delay),
      median_arr_delay = median(arr_delay),
    )
)
```

## Funneling

Being both "eager" and "lazy" at the same time introduces a challenge:
it is too easy to accidentally trigger computation,
which may be prohibitive if an intermediate result is too large.
This is where funneling comes in.

- For unfunneled duckplyr frames, as in the two previous examples the underlying DuckDB computation is carried out upon the first request.
  Once the results are computed, they are cached and subsequent requests are fast.
  This is a good choice for small to medium-sized data, where DuckDB can provide a nice speedup but materializing the data is affordable at any stage.
  This is the default for `duckdb_tibble()` and `as_duckdb_tibble()`.

- For funneled duckplyr frames, accessing a column or requesting the number of rows   triggers an error, either unconditionally, or if the result exceeds a certain size.
  This is a good choice for large data sets where the cost of materializing the data may be prohibitive due to size or computation time, and the user wants to control when the computation is carried out.
  The default for the ingestion functions like `read_parquet_duckdb()` is to limit the result size to one million cells (values in the resulting data frame).

```{r}
year <- 2024
base_url <- "https://blobs.duckdb.org/flight-data-partitioned/"
files <- paste0("Year=", year, "/data_0.parquet")
url <- paste0(base_url, files)
url

duckplyr::db_exec("INSTALL httpfs")
duckplyr::db_exec("LOAD httpfs")

flights_funneled <- duckplyr::read_parquet_duckdb(url)
flights_funneled
class(flights_funneled)
```

In this example, `flights_funneled` is a funneled duckplyr frame.
Accessing a column or requesting the number of rows triggers an error:

```{r error = TRUE}
nrow(flights_funneled)
```

On the other hand, if the results are small enough, e.g., after an aggregation, they can be transparently used as a data frame:

```{r}
flights_count <-
  flights_funneled |> 
  count(Month)

nrow(flights_count)
```

Funneled duckplyr frames behave like [`dtplyr`'s lazy frames](https://dtplyr.tidyverse.org/reference/lazy_dt.html),
or dbplyr's lazy frames:
the computation only starts when you **explicitly** request it with a "collect"
function.
In dtplyr and dbplyr, there are no unfunneled frames: collection always needs to be
explicit.

A funneled duckplyr frame can be converted to an unfunneled one with `as_duckdb_tibble(funnel = FALSE)`.
The [collect.duckplyr_df()] method triggers computation and converts to a plain tibble.
Other useful methods include [compute_file()] for storing results in a file,
and [compute.duckplyr_df()] for storing results in temporary storage on disk.

Beyond safety regarding memory usage, funneled frames also allow you
to check that all operations are supported by DuckDB:
for a funneled frame with `funnel = FALSE`, fallbacks to dplyr are not possible.
As a reminder, computing via DuckDB is currently not always possible,
see `vignette("limits")` for the supported operations.
In such cases, the original dplyr implementation is used, see [fallback] for details.
As the original dplyr implementation accesses columns directly,
the data must be materialized before a fallback can be executed.
This means that automatic fallback is only possible for "unfunneled" duckplyr frames,
while for "funneled" duckplyr frames, one of the aforementioned collection methods must be used first.

## Funneling

The default mode for `as_duckdb_tibble()` is unfunneled.
This allows applying all data frame operations on the results, including column subsetting or retrieving the number of rows.
In addition, if an operation cannot be carried out by duckdb, the dplyr fallback is used transparently.
Use `funnel = TRUE` to ensure that all operations are carried out by DuckDB, or fail.
This is also the default for the ingestion functions such as `read_parquet_duckdb()`.

```{r}
funneled <-
  duckplyr::flights_df() |>
  duckplyr::as_duckdb_tibble(funnel = TRUE)
```

Columns or the row count cannot be accessed directly in this mode:

```{r error = TRUE}
nrow(funneled)
```

Also, operations that are not (yet) supported will fail:

```{r error = TRUE}
funneled |>
  mutate(inflight_delay = arr_delay - dep_delay) |>
  summarize(
    .by = c(year, month),
    mean_inflight_delay = mean(inflight_delay, na.rm = TRUE),
    median_inflight_delay = median(inflight_delay, na.rm = TRUE),
  )
```

See `vignette("limits")` for current limitations, and the contributing guide for how to add support for additional operations.


## How is this different from dbplyr?

The duckplyr package is a dplyr backend that uses DuckDB, a high-performance, embeddable analytical database.
It is designed to be a fully compatible drop-in replacement for dplyr, with *exactly* the same syntax and semantics:

- Input and output are data frames or tibbles.
- All dplyr verbs are supported, with fallback.
- All R data types and functions are supported, with fallback.
- No SQL is generated.

The dbplyr package is a dplyr backend that connects to SQL databases, and is designed to work with various databases that support SQL, including DuckDB.
Data must be copied into and collected from the database, and the syntax and semantics are similar but not identical to plain dplyr.
